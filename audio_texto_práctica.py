# -*- coding: utf-8 -*-
"""Audio_texto_práctica

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CTp4CSs-QFg_XSBi0YvlspPzJYrDQBy3

# Librerías
"""

!pip install transformers
!pip install  pydub    # Librería para ogg a wav
!pip install miniaudio

!pip install SpeechRecognition

!pip install pyaudio

# Librería para cargar el audio

!pip install librosa

!pip install pytorch-transformers

!pip install torch

!pip uninstall torch

"""# Wav2Vec2 Transformer

>Wav2Vec2 de Huggingface


"""

import torch
torch.cuda.is_available()
from transformers import Wav2Vec2Config, Wav2Vec2Model
from transformers import  AutoModelForCTC, Wav2Vec2Processor, AutoTokenizer

# Descargar tokenizer

tokenizer = AutoTokenizer.from_pretrained('facebook/wav2vec2-base-960h')
processor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base-960h')
model =  AutoModelForCTC.from_pretrained('facebook/wav2vec2-base-960h')

"""# Conversión de .ogg a .wav"""

# Para covertir de ogg a wave

from pydub import AudioSegment

input_file = r'/content/Audio_CIMAT/Audios_ogg/tio_audio.ogg'   # Ruta del audio de entrada
output_file = r'/content/Audio_CIMAT/Audios_wav/tio_audio.wav' # Ruta para guardar el archivo de salida

# Cargar el audio
audio = AudioSegment.from_file(input_file)

# Exportar el audio en formato WAVE
audio.export(output_file, format='wav')

print('Conversión del audio finalizada')

import librosa

# extraer el audio
audio_file = r'/content/Audio_CIMAT/Audios_wav/tio_audio.wav'   # Poner la ruta

# Cargar el archivo de audio
audio, sample_rate = librosa.load(audio_file)
duration = librosa.get_duration(y=audio, sr=sample_rate)

# Obtener información del audio
print('Duración el audio:', duration, 'segundos')
print('Frecuencia del audio: ', sample_rate, 'Hz')

"""# Transcripción"""

import speech_recognition as sr
import io

r = sr.Recognizer()

audio_file_path = r'/content/Audio_CIMAT/Audio_CIMAT_wav/tio_audio.wav'
with open(audio_file_path, 'rb') as file:
    audio_data = file.read()

# data = io.BytesIO(audio_file.get_wav_data())  # array de bytes

byte_io = io.BytesIO(audio_data)
clip = AudioSegment.from_file(data)  # numpy array
tensor = torch.FloatTensor(clip.get_array_of_samples())  # Tensor

inputs = tokenizer(tensor, sampling_rate=16000, return_tensors = 'pt', padding='longest').input_values  # Para el modelo
logits = model(inputs).logits
tokens = torch.argmax (logits, axis = -1)
text = tokenizer.batch_decode(tokens)

print('Texto del audio: ', str(text).lower())

